{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b33e107-6723-4e59-8c4d-e9c606639d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers, Input, Model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.mixed_precision import set_global_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1270540-946a-47f4-81c2-b59f74ee02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c798cf38-9cdb-4f12-b611-903042b484c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r\"S:\\Coding\\Python\\MiniProject\\Dataset\\80_20excel\\train.csv\")\n",
    "test_df = pd.read_csv(r\"S:\\Coding\\Python\\MiniProject\\Dataset\\80_20excel\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377f699d-1617-4109-a6a5-c5475f905547",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "train_df['gender_encoded'] = le.fit_transform(train_df['gender'])\n",
    "test_df['gender_encoded'] = le.transform(test_df['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80849eb9-25aa-471c-8457-50eaa7163b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7993d4a-eebe-47d3-8d80-fcf40f96df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(image_dir, ids):\n",
    "    images = []\n",
    "    for img_id in tqdm(ids):\n",
    "        img_path = os.path.join(image_dir, str(img_id) + \".png\")\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = image.resize(IMG_SIZE)\n",
    "        image = img_to_array(image)\n",
    "        image = preprocess_input(image)\n",
    "        images.append(image)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de73afc0-6cb9-4eac-b09c-cbf56459dbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = load_images(r\"S:\\Coding\\Python\\MiniProject\\Dataset\\80_20image\\train\", train_df['id'])\n",
    "test_images = load_images(r\"S:\\Coding\\Python\\MiniProject\\Dataset\\80_20image\\test\", test_df['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44b2f6b-5735-4732-a555-c89bd05dde24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gender = train_df['gender_encoded'].values\n",
    "test_gender = test_df['gender_encoded'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec09cda-b50e-4728-b361-dc305b148ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['year'].values\n",
    "y_test = test_df['year'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350de243-5e4c-4eef-abcd-70734d7a79f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import (Input, GlobalAveragePooling2D, Dense, Concatenate,\n",
    "                                     Multiply, Add, Activation, Conv2D, Reshape)\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "image_input = Input(shape=(128, 128, 3))\n",
    "base_model = MobileNetV2(include_top=False, weights='imagenet', input_tensor=image_input)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "meta_input = Input(shape=(1,))\n",
    "x = Concatenate()([x, meta_input])\n",
    "\n",
    "# Dense layers\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=[image_input, meta_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ca747c-79e6-4e30-bf01-0d40252bddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = ModelCheckpoint(\n",
    "    filepath=r'S:\\Coding\\Python\\MiniProject\\Models\\HybridModel3\\epoch_{epoch:02d}_valmae_{val_mae:.2f}.h5',\n",
    "    save_freq='epoch',\n",
    "    save_weights_only=False,\n",
    "    save_best_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6bb122-575d-4164-8851-97f6a16df932",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    [train_images, train_gender], y_train,\n",
    "    validation_data=([test_images, test_gender], y_test),\n",
    "    epochs=40,\n",
    "    batch_size=8,\n",
    "    callbacks=[early_stop, lr_scheduler, checkpoint_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce52663b-999b-4975-bd8b-faa7ec7ef2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'S:\\Coding\\Python\\MiniProject\\Models\\HybridModel3')\n",
    "model.save(r'S:\\Coding\\Python\\MiniProject\\Models\\HybridModel3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07255913-373d-4401-bfc2-c55fa4696d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_history2.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "print(\"Training complete. History saved as 'training_history.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
